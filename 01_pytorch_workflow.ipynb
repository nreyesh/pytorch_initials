{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad073e6-b9af-43be-9a5e-3ea11466ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba997e4-ae48-4e1a-a845-4ef1bd290a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "373fd963-dbf5-418d-973a-1038f6046968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Labels\n",
    "A = torch.tensor([[1,2],[3,4]],dtype=torch.float32)\n",
    "B = torch.tensor([[5,6],[7,8]], dtype=torch.float32)\n",
    "\n",
    "X = torch.cat((A,B),0)\n",
    "#X = torch.stack((A,B),0)\n",
    "y = torch.tensor([0,0,1,1],dtype=torch.float32)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd334a8f-b5ab-40c8-b938-5364768a351b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d9e35af-2447-4d95-a688-81ce1e88a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size): \n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        # layers\n",
    "        self.fc1 = nn.Linear(input_size,hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Activation Function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d0acbf1-74f8-48cb-ae6d-a7d6875d4e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 4\n",
    "output_size = 2\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d84aaa0-3a8d-40c3-999a-64552bab919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4099fbeb-f9a0-4091-9cbc-eb516fb64c09",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one_hot is only applicable to index tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# convert to one-hot encoding\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#y_one_hot = torch.zeros(len(y), 2)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#y_one_hot.scatter_(1, y.unsqueeze(1).to(torch.int64), 1.0)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m      7\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one_hot is only applicable to index tensor."
     ]
    }
   ],
   "source": [
    "# convert to one-hot encoding\n",
    "#y_one_hot = torch.zeros(len(y), 2)\n",
    "#y_one_hot.scatter_(1, y.unsqueeze(1).to(torch.int64), 1.0)\n",
    "y_one_hot = nn.functional.one_hot(y)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    X = X.cuda()\n",
    "    y_one_hot = y_one_hot.cuda()\n",
    "\n",
    "X.device, y_one_hot.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "12f3d0e7-ac2d-4950-837c-54b81c47a359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(X.dtype, y_one_hot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48c11ba6-05f5-4814-8918-e7ee47cbece5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Loss: 0.7550421953201294\n",
      "Epoch 20/100, Loss: 0.7457253932952881\n",
      "Epoch 30/100, Loss: 0.7367979288101196\n",
      "Epoch 40/100, Loss: 0.72788006067276\n",
      "Epoch 50/100, Loss: 0.7189001441001892\n",
      "Epoch 60/100, Loss: 0.7091460227966309\n",
      "Epoch 70/100, Loss: 0.6926745772361755\n",
      "Epoch 80/100, Loss: 0.6849929094314575\n",
      "Epoch 90/100, Loss: 0.6781398057937622\n",
      "Epoch 100/100, Loss: 0.6714069843292236\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "epochs=100\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs=model(X)\n",
    "    loss = criterion(outputs,y_one_hot)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1)%10 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f3f1e-9b29-4965-b245-1606c6de7a9c",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59eea19e-0d3a-4315-a8de-d718e7facf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad4f7d3a-1a08-48b7-9739-0d4669c572d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0200],\n",
       "        [0.0400],\n",
       "        [0.0600],\n",
       "        [0.0800],\n",
       "        [0.1000],\n",
       "        [0.1200],\n",
       "        [0.1400],\n",
       "        [0.1600],\n",
       "        [0.1800],\n",
       "        [0.2000],\n",
       "        [0.2200],\n",
       "        [0.2400],\n",
       "        [0.2600],\n",
       "        [0.2800],\n",
       "        [0.3000],\n",
       "        [0.3200],\n",
       "        [0.3400],\n",
       "        [0.3600],\n",
       "        [0.3800],\n",
       "        [0.4000],\n",
       "        [0.4200],\n",
       "        [0.4400],\n",
       "        [0.4600],\n",
       "        [0.4800],\n",
       "        [0.5000],\n",
       "        [0.5200],\n",
       "        [0.5400],\n",
       "        [0.5600],\n",
       "        [0.5800],\n",
       "        [0.6000],\n",
       "        [0.6200],\n",
       "        [0.6400],\n",
       "        [0.6600],\n",
       "        [0.6800],\n",
       "        [0.7000],\n",
       "        [0.7200],\n",
       "        [0.7400],\n",
       "        [0.7600],\n",
       "        [0.7800],\n",
       "        [0.8000],\n",
       "        [0.8200],\n",
       "        [0.8400],\n",
       "        [0.8600],\n",
       "        [0.8800],\n",
       "        [0.9000],\n",
       "        [0.9200],\n",
       "        [0.9400],\n",
       "        [0.9600],\n",
       "        [0.9800]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start,end,step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f23fa8a-ba5c-4210-ac19-9640c23c0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:id],y[:id]\n",
    "X_test, y_test = X[id:], y[id:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c62e1c88-72a1-4df3-b704-559c4478ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad=True,\n",
    "                                             dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                           requires_grad=True,\n",
    "                                           dtype=torch.float32))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "00affb28-34f3-49fe-bc0b-7ce651ea6707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed (42)\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "806d1b8e-5c30-40b3-ab45-a4dc88d0749b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List name Parameters\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb666731-6a1a-4f6d-a30e-00d57ba25323",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediccion\n",
    "with torch.inference_mode():\n",
    "    y_pred = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba138768-72d4-40bd-a400-a4a06e840e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3982],\n",
       "         [0.4049],\n",
       "         [0.4116],\n",
       "         [0.4184],\n",
       "         [0.4251],\n",
       "         [0.4318],\n",
       "         [0.4386],\n",
       "         [0.4453],\n",
       "         [0.4520],\n",
       "         [0.4588]]),\n",
       " tensor([[0.8600],\n",
       "         [0.8740],\n",
       "         [0.8880],\n",
       "         [0.9020],\n",
       "         [0.9160],\n",
       "         [0.9300],\n",
       "         [0.9440],\n",
       "         [0.9580],\n",
       "         [0.9720],\n",
       "         [0.9860]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f1214e5b-243c-4438-b6d9-f0cd0f177523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Definici√≥n de optimizadores\n",
    "optim_adam = Adam(params=model.parameters(),\n",
    "                 lr=0.01)\n",
    "optim_sgd = SGD(params=model.parameters(),\n",
    "               lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0d61ab10-bdef-4f6b-983e-488dc35d8d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2711813449859619\n",
      "Epoch: 0 / Train Loss: 0.2711813449859619 / Test Loss: 0.418936163187027\n",
      "OrderedDict([('weights', tensor([0.3767])), ('bias', tensor([0.1688]))])\n",
      "loss: 0.2572813332080841\n",
      "loss: 0.2433813512325287\n",
      "loss: 0.22948133945465088\n",
      "loss: 0.21558134257793427\n",
      "loss: 0.20168134570121765\n",
      "Epoch: 5 / Train Loss: 0.20168134570121765 / Test Loss: 0.324436217546463\n",
      "OrderedDict([('weights', tensor([0.4267])), ('bias', tensor([0.2188]))])\n",
      "loss: 0.18778134882450104\n",
      "loss: 0.17388132214546204\n",
      "loss: 0.15998134016990662\n",
      "loss: 0.1460813283920288\n",
      "loss: 0.1321813315153122\n",
      "Epoch: 10 / Train Loss: 0.1321813315153122 / Test Loss: 0.22993624210357666\n",
      "OrderedDict([('weights', tensor([0.4767])), ('bias', tensor([0.2688]))])\n",
      "loss: 0.11828134208917618\n",
      "loss: 0.10438136011362076\n",
      "loss: 0.09048136323690414\n",
      "loss: 0.07658137381076813\n",
      "loss: 0.06345288455486298\n",
      "Epoch: 15 / Train Loss: 0.06345288455486298 / Test Loss: 0.13554081320762634\n",
      "OrderedDict([('weights', tensor([0.5267])), ('bias', tensor([0.3187]))])\n",
      "loss: 0.051896534860134125\n",
      "loss: 0.042198795825242996\n",
      "loss: 0.03463803231716156\n",
      "loss: 0.02947370707988739\n",
      "loss: 0.026887917891144753\n",
      "Epoch: 20 / Train Loss: 0.026887917891144753 / Test Loss: 0.04859854653477669\n",
      "OrderedDict([('weights', tensor([0.5751])), ('bias', tensor([0.3626]))])\n",
      "loss: 0.026886994019150734\n",
      "loss: 0.029275041073560715\n",
      "loss: 0.03341194987297058\n",
      "loss: 0.03821286931633949\n",
      "loss: 0.042151737958192825\n",
      "Epoch: 25 / Train Loss: 0.042151737958192825 / Test Loss: 0.0053053200244903564\n",
      "OrderedDict([('weights', tensor([0.6052])), ('bias', tensor([0.3811]))])\n",
      "loss: 0.04409855231642723\n",
      "loss: 0.044207725673913956\n",
      "loss: 0.04269247502088547\n",
      "loss: 0.03973929211497307\n",
      "loss: 0.03560928255319595\n",
      "Epoch: 30 / Train Loss: 0.03560928255319595 / Test Loss: 0.0190095417201519\n",
      "OrderedDict([('weights', tensor([0.6013])), ('bias', tensor([0.3688]))])\n",
      "loss: 0.03138422966003418\n",
      "loss: 0.027755435556173325\n",
      "loss: 0.025042256340384483\n",
      "loss: 0.0233253575861454\n",
      "loss: 0.022502493113279343\n",
      "Epoch: 35 / Train Loss: 0.022502493113279343 / Test Loss: 0.05434228852391243\n",
      "OrderedDict([('weights', tensor([0.5883])), ('bias', tensor([0.3450]))])\n",
      "loss: 0.02235237881541252\n",
      "loss: 0.02264046110212803\n",
      "loss: 0.023137930780649185\n",
      "loss: 0.0235992930829525\n",
      "loss: 0.023901548236608505\n",
      "Epoch: 40 / Train Loss: 0.023901548236608505 / Test Loss: 0.06803224980831146\n",
      "OrderedDict([('weights', tensor([0.5910])), ('bias', tensor([0.3290]))])\n",
      "loss: 0.023897875100374222\n",
      "loss: 0.02351686730980873\n",
      "loss: 0.022750496864318848\n",
      "loss: 0.021631404757499695\n",
      "loss: 0.02023867890238762\n",
      "Epoch: 45 / Train Loss: 0.02023867890238762 / Test Loss: 0.05248771980404854\n",
      "OrderedDict([('weights', tensor([0.6111])), ('bias', tensor([0.3266]))])\n",
      "loss: 0.018676312640309334\n",
      "loss: 0.017085570842027664\n",
      "loss: 0.015601828694343567\n",
      "loss: 0.014375993981957436\n"
     ]
    }
   ],
   "source": [
    "### Training Loop\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    # 0. Modo entrenamiento, setea todos los parametros que requieren gradiente. \n",
    "    model.train() \n",
    "    \n",
    "    # 1. Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # 2. Calculo del Error \n",
    "    loss = loss_fn(y_pred,y_train)\n",
    "    print(f'loss: {loss}')\n",
    "\n",
    "    # 3. Resetea el \n",
    "    optim_adam.zero_grad()\n",
    "\n",
    "    # 4. BackPropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Calculo del Gradiente\n",
    "    optim_adam.step()\n",
    "    \n",
    "    model.eval() # apaga el seguimiento del gradiente\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model(X_test)\n",
    "        loss_test = loss_fn(test_pred,y_test)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch: {epoch} / Train Loss: {loss} / Test Loss: {loss_test}')\n",
    "        print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91175f45-8957-4bf2-bf54-e7ffaa320351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5962],\n",
       "        [0.6051],\n",
       "        [0.6140],\n",
       "        [0.6230],\n",
       "        [0.6319],\n",
       "        [0.6408],\n",
       "        [0.6498],\n",
       "        [0.6587],\n",
       "        [0.6676],\n",
       "        [0.6766]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(X_test)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
