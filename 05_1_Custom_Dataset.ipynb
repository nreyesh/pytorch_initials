{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMlhDGXoUy1YYkn65whQNX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nreyesh/pytorch_initials/blob/main/05_1_Custom_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNkNDeqXih0A",
        "outputId": "114a140f-0c0c-4a60-8ce6-8072192e9b07"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=adba3fd2a4a5b030eb4a38760a5622a6825bfa3c3d5ef9d48e18f05b69dda6a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Getting the Dataset"
      ],
      "metadata": {
        "id": "4pyBjOI9iihz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wGSCsaGBhg2c",
        "outputId": "2c5f94d1-3cfc-44c8-fe6a-4f818c6755c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pizza_steak_sushi.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "import wget\n",
        "\n",
        "url = 'https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip'\n",
        "wget.download(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path('dataset/')\n",
        "zip_path = '/content/pizza_steak_sushi.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    if not os.path.isdir(data_path):\n",
        "        os.mkdir(data_path)\n",
        "    zip_ref.extractall(data_path)"
      ],
      "metadata": {
        "id": "p2ZFkw8Bi0ql"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Loading the Data\n",
        "### Option 1: Image Loader"
      ],
      "metadata": {
        "id": "LlNmvkZTv6bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "train_dir = data_path / 'train'\n",
        "test_dir = data_path / 'test'\n",
        "\n",
        "img_size = 64\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "        transforms.Resize(size=(img_size,img_size)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor()\n",
        "      ])\n",
        "test_transforms = transforms.Compose([\n",
        "        transforms.Resize(size=(img_size,img_size)),\n",
        "        transforms.ToTensor()\n",
        "      ])\n",
        "\n",
        "train_imageFolder = ImageFolder(train_dir,\n",
        "                                transform=train_transforms)\n",
        "\n",
        "test_imageFolder = ImageFolder(test_dir,\n",
        "                               transform=test_transforms)"
      ],
      "metadata": {
        "id": "y_fFcabquqA-"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imageFolder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naziYbru10gi",
        "outputId": "b6540751-3a47-4980-9c1a-b799ad8bd242"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 225\n",
              "    Root location: dataset/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=warn)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imageFolder.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXWxY7z1YzX",
        "outputId": "ff5d4f25-92c8-4dbf-d907-6d21fd78cbc6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pizza', 'steak', 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imageFolder.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur_e9n2c1wXw",
        "outputId": "026b1eaf-0e6b-45d1-b24c-2233a88b6a6e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pizza': 0, 'steak': 1, 'sushi': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imageFolder[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkplhf_05QiJ",
        "outputId": "277f82be-11fa-4348-8f00-c367deb138b5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.1137, 0.1137, 0.1059,  ..., 0.1098, 0.1098, 0.1137],\n",
              "          [0.1137, 0.1098, 0.1059,  ..., 0.1216, 0.1216, 0.1255],\n",
              "          [0.1098, 0.1059, 0.1020,  ..., 0.1294, 0.1294, 0.1333],\n",
              "          ...,\n",
              "          [0.0824, 0.0863, 0.0902,  ..., 0.1647, 0.1686, 0.1765],\n",
              "          [0.0902, 0.0863, 0.0824,  ..., 0.1647, 0.1686, 0.1765],\n",
              "          [0.0863, 0.0824, 0.0824,  ..., 0.1569, 0.1569, 0.1608]],\n",
              " \n",
              "         [[0.0706, 0.0745, 0.0706,  ..., 0.0549, 0.0549, 0.0588],\n",
              "          [0.0745, 0.0706, 0.0745,  ..., 0.0627, 0.0627, 0.0627],\n",
              "          [0.0745, 0.0745, 0.0745,  ..., 0.0627, 0.0627, 0.0667],\n",
              "          ...,\n",
              "          [0.1059, 0.1098, 0.1098,  ..., 0.2275, 0.2275, 0.2314],\n",
              "          [0.1059, 0.1020, 0.1020,  ..., 0.2275, 0.2314, 0.2314],\n",
              "          [0.1020, 0.0980, 0.0980,  ..., 0.2353, 0.2275, 0.2275]],\n",
              " \n",
              "         [[0.0941, 0.0980, 0.0902,  ..., 0.0196, 0.0196, 0.0196],\n",
              "          [0.0941, 0.0941, 0.0902,  ..., 0.0235, 0.0235, 0.0235],\n",
              "          [0.0941, 0.0941, 0.0902,  ..., 0.0196, 0.0157, 0.0196],\n",
              "          ...,\n",
              "          [0.1059, 0.1098, 0.1059,  ..., 0.1765, 0.1765, 0.1843],\n",
              "          [0.1098, 0.1020, 0.0980,  ..., 0.1765, 0.1804, 0.1804],\n",
              "          [0.1059, 0.1020, 0.0980,  ..., 0.1765, 0.1725, 0.1725]]]),\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_imageFolder,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_imageFolder,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=True)"
      ],
      "metadata": {
        "id": "m7rDpFTu21LV"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, labels = next(iter(train_loader))\n",
        "len(imgs), len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBiqUxLp5JZN",
        "outputId": "eebf1a88-a299-492f-db94-534d23ffb0e1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5qWZTZAZeO4",
        "outputId": "632abac2-210d-467b-cda4-2ef9d9c39b23"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2 Custom Image Loader"
      ],
      "metadata": {
        "id": "kJqrscDR53GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aux = Path('dataset/train/').glob('*/*.jpg')\n",
        "aux = list(aux)\n",
        "aux"
      ],
      "metadata": {
        "id": "IsGt1ejN8e5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomImageLoader(Dataset):\n",
        "  def __init__(self, root_directory, transform=None):\n",
        "    super().__init__()\n",
        "    self.paths = list(Path(root_directory).glob('*/*.jpg'))\n",
        "    self.transforms = transform\n",
        "    self.classes = sorted([x.parts[-1] for x in Path(root_directory).iterdir() if x.is_dir()])\n",
        "    self.class_to_idx = {key:idx for idx,key in enumerate(self.classes)}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.paths[idx])\n",
        "    label_name = self.paths[idx].parts[-2]\n",
        "    label = self.class_to_idx[label_name]\n",
        "\n",
        "    if transforms:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "UJDtWJtO52FG"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_customImageLoader = CustomImageLoader('dataset/train/',\n",
        "                                            transform=train_transforms)\n",
        "test_customImageLoader = CustomImageLoader('dataset/test/',\n",
        "                                            transform=test_transforms)"
      ],
      "metadata": {
        "id": "_nllAar89rXz"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_customImageLoader.paths"
      ],
      "metadata": {
        "id": "hlJNLDJB9-XA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85146de-2e0a-4f54-fbc5-6426c395359d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.CustomImageLoader at 0x785a38d06e60>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_customImageLoader.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HAkzLq4AcWg",
        "outputId": "e5522aed-15af-4337-d53e-76a6fe8af7f1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pizza', 'steak', 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_customImageLoader.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y8GNhHqA5c-",
        "outputId": "22a33a4a-d3b7-4659-a709-acddb2d50a1a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pizza': 0, 'steak': 1, 'sushi': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_customImageLoader[0]\n",
        "img.shape, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smV9X5EfCmSB",
        "outputId": "2fadc37b-1cf4-4e78-a8bc-976bf4f54a1a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 128, 128]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_customDataLoader = DataLoader(train_customImageLoader,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=True)\n",
        "test_customDataLoader = DataLoader(test_customImageLoader,\n",
        "                                   batch_size=BATCH_SIZE,\n",
        "                                   shuffle=True)"
      ],
      "metadata": {
        "id": "t8bBywi0DHaL"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, labels = next(iter(train_customDataLoader))\n",
        "imgs.shape, labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKnCQrOdD8Om",
        "outputId": "c011c6da-baa0-487b-bcbe-395476d2b499"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 3, 64, 64]), torch.Size([16]))"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_customDataLoader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef12i-wAZ3AE",
        "outputId": "74796f34-0364-4f59-ffc9-e4fd91853dbc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Visualization"
      ],
      "metadata": {
        "id": "-ce97ETiELVv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AD7RO1yOEPz6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7s6gH8MBBuBl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7qK0D_8eBud5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class MiniVGG(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels,\n",
        "               im_size,\n",
        "               hidden_channels,\n",
        "               n_classes ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels,\n",
        "                      out_channels=hidden_channels,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.Conv2d(in_channels=hidden_channels,\n",
        "                      out_channels=hidden_channels,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),\n",
        "                          stride=2,\n",
        "                          padding=0),\n",
        "            nn.Dropout(0.1)\n",
        "          )\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_channels,\n",
        "                      out_channels=hidden_channels*2,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(hidden_channels*2),\n",
        "            nn.Conv2d(in_channels=hidden_channels*2,\n",
        "                      out_channels=hidden_channels*2,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(hidden_channels*2),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),\n",
        "                          stride=2,\n",
        "                          padding=1),\n",
        "            nn.Dropout(0.1)\n",
        "            )\n",
        "\n",
        "    self.linear = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_channels*2*16*16,\n",
        "                  out_features=512),\n",
        "        nn.Linear(in_features=512,\n",
        "                  out_features=n_classes),\n",
        "        nn.Softmax()\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.linear(x)\n",
        "    return x\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = MiniVGG(3,32,32,3).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fZ9vd3zBukg",
        "outputId": "9650eb3d-d472-48f8-e1ef-e7cfe34629f3"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (linear): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=16384, out_features=512, bias=True)\n",
              "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
              "    (3): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.randn(1,3,64,64).to(device)\n",
        "pass_1 = model.block_1(img)\n",
        "pass_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EtAGmkUJRL-",
        "outputId": "e2118bdb-5b39-45b6-928c-6ad327a47b1c"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pass_2 = model.block_2(pass_1)\n",
        "pass_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTl5OaTfKp2d",
        "outputId": "a437c965-86a2-462b-e555-ba32f387718d"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pass_3 = model.linear(pass_2)\n",
        "pass_3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo_SH9C6LpJ8",
        "outputId": "e58a1732-5857-4c99-df09-b3245945de31"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pass_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqe8Rcs3Ohab",
        "outputId": "d88e14d7-553b-4683-c99c-217b542c9290"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1534, 0.2736, 0.5730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "_hFxQE_4PTUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KE3nbHBXJSO",
        "outputId": "bca994af-7449-4a37-f29f-1c290ec150e8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "143n10q_OiFL"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from torcheval.metrics import MulticlassAccuracy\n",
        "\n",
        "epochs = 100\n",
        "metric = MulticlassAccuracy()\n",
        "\n",
        "model = MiniVGG(3,128,32,3).to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f'# Epoch: {epoch}')\n",
        "  # Train Initialization\n",
        "  model.train()\n",
        "  loss_acum, acc_acum = 0, 0\n",
        "  for X,y in train_customDataLoader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # 1. Predictions\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # 2. Loss calculation\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    loss_acum += loss\n",
        "\n",
        "    metric.update(y_pred,y)\n",
        "    acc_acum += metric.compute()\n",
        "\n",
        "    # 3. Gradient reset\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Gradient Calculation\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Updating weights\n",
        "    optimizer.step()\n",
        "\n",
        "  loss_acum /= len(train_customDataLoader)\n",
        "  acc_acum /= len(train_customDataLoader)\n",
        "\n",
        "  print(f'Train loss: {loss_acum:.5f} | Train accuracy: {acc_acum:.2f}')\n",
        "\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    loss_acum, acc_acum = 0, 0\n",
        "    for X,y in test_customDataLoader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      # 1. Predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # 2. Loss calculation\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      loss_acum += loss\n",
        "\n",
        "      metric.update(y_pred,y)\n",
        "      acc_acum += metric.compute()\n",
        "\n",
        "    loss_acum /= len(test_customDataLoader)\n",
        "    acc_acum /= len(test_customDataLoader)\n",
        "\n",
        "    print(f'Test loss: {loss_acum:.5f} | Test accuracy: {acc_acum:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ6FNFuZUGhK",
        "outputId": "470eb4bf-3be6-4199-dd73-d82ce80b3b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Epoch: 0\n",
            "Train loss: 1.09445 | Train accuracy: 0.41\n",
            "Test loss: 1.10206 | Test accuracy: 0.35\n",
            "# Epoch: 1\n",
            "Train loss: 1.10702 | Train accuracy: 0.33\n",
            "Test loss: 1.10230 | Test accuracy: 0.33\n",
            "# Epoch: 2\n",
            "Train loss: 1.09844 | Train accuracy: 0.32\n",
            "Test loss: 1.10889 | Test accuracy: 0.33\n",
            "# Epoch: 3\n",
            "Train loss: 1.11066 | Train accuracy: 0.33\n",
            "Test loss: 1.11563 | Test accuracy: 0.32\n",
            "# Epoch: 4\n",
            "Train loss: 1.11512 | Train accuracy: 0.32\n",
            "Test loss: 1.11636 | Test accuracy: 0.32\n",
            "# Epoch: 5\n",
            "Train loss: 1.09845 | Train accuracy: 0.32\n",
            "Test loss: 1.11571 | Test accuracy: 0.32\n",
            "# Epoch: 6\n",
            "Train loss: 1.11828 | Train accuracy: 0.32\n",
            "Test loss: 1.12152 | Test accuracy: 0.32\n",
            "# Epoch: 7\n",
            "Train loss: 1.11047 | Train accuracy: 0.32\n",
            "Test loss: 1.11877 | Test accuracy: 0.32\n",
            "# Epoch: 8\n",
            "Train loss: 1.11304 | Train accuracy: 0.32\n",
            "Test loss: 1.11696 | Test accuracy: 0.32\n",
            "# Epoch: 9\n",
            "Train loss: 1.09722 | Train accuracy: 0.32\n",
            "Test loss: 1.12017 | Test accuracy: 0.32\n",
            "# Epoch: 10\n",
            "Train loss: 1.09864 | Train accuracy: 0.32\n",
            "Test loss: 1.11344 | Test accuracy: 0.32\n",
            "# Epoch: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K6KTukWuf6tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_customDataLoader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1mRk8azbr4n",
        "outputId": "ad7c04b7-832d-4aef-9022-3e386bf04359"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    }
  ]
}