{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjxHoEqfJp6HQQMZq9rTht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nreyesh/pytorch_initials/blob/main/05_1_Custom_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNkNDeqXih0A",
        "outputId": "97334581-3bae-4537-8610-b99808ee0459"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=79537616c784e97cbd3176e6704bb3cd9a0c2bca1ee665da4a35589b1dd6650c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Getting the Dataset"
      ],
      "metadata": {
        "id": "4pyBjOI9iihz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wGSCsaGBhg2c",
        "outputId": "ff739c5e-af5e-4ec3-d294-1f55792f1ccd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pizza_steak_sushi.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import wget\n",
        "\n",
        "url = 'https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip'\n",
        "wget.download(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "data_path = Path('dataset/')\n",
        "zip_path = '/content/pizza_steak_sushi.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    if not os.path.isdir(data_path):\n",
        "        os.mkdir(data_path)\n",
        "    zip_ref.extractall(data_path)"
      ],
      "metadata": {
        "id": "p2ZFkw8Bi0ql"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Loading the Data\n",
        "### Option 1: Image Loader"
      ],
      "metadata": {
        "id": "LlNmvkZTv6bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "train_dir = data_path / 'train'\n",
        "test_dir = data_path / 'test'\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "        transforms.Resize(size=(128,128)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor()\n",
        "      ])\n",
        "test_transforms = transforms.Compose([\n",
        "        transforms.Resize(size=(128,128)),\n",
        "        transforms.ToTensor()\n",
        "      ])\n",
        "\n",
        "train_imageFolder = ImageFolder(train_dir,\n",
        "                                transform=train_transforms)\n",
        "\n",
        "test_imageFolder = ImageFolder(test_dir,\n",
        "                               transform=test_transforms)"
      ],
      "metadata": {
        "id": "y_fFcabquqA-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imageFolder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naziYbru10gi",
        "outputId": "b22e2fd1-1b98-4ac7-8386-97e3c999b169"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 225\n",
              "    Root location: dataset/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(128, 128), interpolation=bilinear, max_size=None, antialias=warn)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imageFolder.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXWxY7z1YzX",
        "outputId": "0561aa96-aad9-4186-fb0c-3233ecc31531"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pizza', 'steak', 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imageFolder.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur_e9n2c1wXw",
        "outputId": "a0075aee-5eda-4116-cad7-6f0fd7a00767"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pizza': 0, 'steak': 1, 'sushi': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imageFolder[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkplhf_05QiJ",
        "outputId": "f3b9c8c2-face-4239-e9cb-71b54f1cfe0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.1137, 0.1137, 0.1059,  ..., 0.1098, 0.1098, 0.1137],\n",
              "          [0.1137, 0.1098, 0.1059,  ..., 0.1216, 0.1216, 0.1255],\n",
              "          [0.1098, 0.1059, 0.1020,  ..., 0.1294, 0.1294, 0.1333],\n",
              "          ...,\n",
              "          [0.0824, 0.0863, 0.0902,  ..., 0.1647, 0.1686, 0.1765],\n",
              "          [0.0902, 0.0863, 0.0824,  ..., 0.1647, 0.1686, 0.1765],\n",
              "          [0.0863, 0.0824, 0.0824,  ..., 0.1569, 0.1569, 0.1608]],\n",
              " \n",
              "         [[0.0706, 0.0745, 0.0706,  ..., 0.0549, 0.0549, 0.0588],\n",
              "          [0.0745, 0.0706, 0.0745,  ..., 0.0627, 0.0627, 0.0627],\n",
              "          [0.0745, 0.0745, 0.0745,  ..., 0.0627, 0.0627, 0.0667],\n",
              "          ...,\n",
              "          [0.1059, 0.1098, 0.1098,  ..., 0.2275, 0.2275, 0.2314],\n",
              "          [0.1059, 0.1020, 0.1020,  ..., 0.2275, 0.2314, 0.2314],\n",
              "          [0.1020, 0.0980, 0.0980,  ..., 0.2353, 0.2275, 0.2275]],\n",
              " \n",
              "         [[0.0941, 0.0980, 0.0902,  ..., 0.0196, 0.0196, 0.0196],\n",
              "          [0.0941, 0.0941, 0.0902,  ..., 0.0235, 0.0235, 0.0235],\n",
              "          [0.0941, 0.0941, 0.0902,  ..., 0.0196, 0.0157, 0.0196],\n",
              "          ...,\n",
              "          [0.1059, 0.1098, 0.1059,  ..., 0.1765, 0.1765, 0.1843],\n",
              "          [0.1098, 0.1020, 0.0980,  ..., 0.1765, 0.1804, 0.1804],\n",
              "          [0.1059, 0.1020, 0.0980,  ..., 0.1765, 0.1725, 0.1725]]]),\n",
              " 0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "train_loader = DataLoader(train_imageFolder,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_imageFolder,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=True)"
      ],
      "metadata": {
        "id": "m7rDpFTu21LV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, labels = next(iter(train_loader))\n",
        "len(imgs), len(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBiqUxLp5JZN",
        "outputId": "aaf97557-29e2-4031-9b24-e68599ba66d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2 Custom Image Loader"
      ],
      "metadata": {
        "id": "kJqrscDR53GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aux = Path('dataset/train/').glob('*/*.jpg')\n",
        "aux = list(aux)\n",
        "aux"
      ],
      "metadata": {
        "id": "IsGt1ejN8e5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomImageLoader(Dataset):\n",
        "  def __init__(self, root_directory, transform=None):\n",
        "    super().__init__()\n",
        "    self.paths = list(Path(root_directory).glob('*/*.jpg'))\n",
        "    self.transforms = transform\n",
        "    self.classes = sorted([x.parts[-1] for x in Path(root_directory).iterdir() if x.is_dir()])\n",
        "    self.class_to_idx = {key:idx for idx,key in enumerate(self.classes)}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.paths)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.paths[idx])\n",
        "    label_name = self.paths[idx].parts[-2]\n",
        "    label = self.class_to_idx[label_name]\n",
        "\n",
        "    if transforms:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    return img, label\n"
      ],
      "metadata": {
        "id": "UJDtWJtO52FG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_customImageLoader = CustomImageLoader('dataset/train/',\n",
        "                                            transform=train_transforms)\n",
        "test_customImageLoader = CustomImageLoader('dataset/test/',\n",
        "                                            transform=test_transforms)"
      ],
      "metadata": {
        "id": "_nllAar89rXz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_customImageLoader.paths"
      ],
      "metadata": {
        "id": "hlJNLDJB9-XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_customImageLoader.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HAkzLq4AcWg",
        "outputId": "46b2bb16-8880-4735-ec08-f62848f1db37"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pizza', 'steak', 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_customImageLoader.class_to_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y8GNhHqA5c-",
        "outputId": "9275eece-3fc0-46aa-bef9-4319ec3159e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pizza': 0, 'steak': 1, 'sushi': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_customImageLoader[0]\n",
        "img.shape, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smV9X5EfCmSB",
        "outputId": "4af546c2-36ac-49fd-bf5d-3cad05140aa0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 128, 128]), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_customDataLoader = DataLoader(train_customImageLoader,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=True)\n",
        "test_customDataLoader = DataLoader(test_customImageLoader,\n",
        "                                   batch_size=BATCH_SIZE,\n",
        "                                   shuffle=True)"
      ],
      "metadata": {
        "id": "t8bBywi0DHaL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, labels = next(iter(train_customDataLoader))\n",
        "imgs.shape, labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKnCQrOdD8Om",
        "outputId": "66b54155-4150-4fd2-f488-b8025f1ca4b1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 3, 128, 128]), torch.Size([8]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Visualization"
      ],
      "metadata": {
        "id": "-ce97ETiELVv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AD7RO1yOEPz6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7s6gH8MBBuBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7qK0D_8eBud5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class MiniVGG(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels,\n",
        "               im_size,\n",
        "               hidden_channels,\n",
        "               n_classes ):\n",
        "    super().__init__()\n",
        "\n",
        "    self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels,\n",
        "                      out_channels=hidden_channels,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.Conv2d(in_channels=hidden_channels,\n",
        "                      out_channels=hidden_channels,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),\n",
        "                          stride=2,\n",
        "                          padding=0),\n",
        "            nn.Dropout(0.1)\n",
        "          )\n",
        "\n",
        "    self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_channels,\n",
        "                      out_channels=hidden_channels*2,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(hidden_channels*2),\n",
        "            nn.Conv2d(in_channels=hidden_channels*2,\n",
        "                      out_channels=hidden_channels*2,\n",
        "                      kernel_size=(3,3),\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(hidden_channels*2),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),\n",
        "                          stride=2,\n",
        "                          padding=1),\n",
        "            nn.Dropout(0.1)\n",
        "            )\n",
        "\n",
        "    self.linear = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_channels*2*32*32,\n",
        "                  out_features=512),\n",
        "        nn.Linear(in_features=512,\n",
        "                  out_features=n_classes),\n",
        "        nn.Softmax()\n",
        "        )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block_1(x)\n",
        "    x = self.block_2(x)\n",
        "    x = self.linear(x)\n",
        "    return x\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = MiniVGG(3,128,32,3).to(device)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fZ9vd3zBukg",
        "outputId": "ba69c68c-0162-4291-85ac-f98d0e59744a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): MaxPool2d(kernel_size=(2, 2), stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (7): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (linear): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=65536, out_features=512, bias=True)\n",
              "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
              "    (3): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.randn(1,3,128,128).to(device)\n",
        "pass_1 = model.block_1(img)\n",
        "pass_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EtAGmkUJRL-",
        "outputId": "3f950177-3e93-49c7-b994-45336a62a0fd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pass_2 = model.block_2(pass_1)\n",
        "pass_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTl5OaTfKp2d",
        "outputId": "0500592f-94fc-4f29-cb58-a5626f7b35d2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pass_3 = model.linear(pass_2)\n",
        "pass_3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo_SH9C6LpJ8",
        "outputId": "4e84a85f-2e45-47e7-e882-2412061a0585"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pass_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqe8Rcs3Ohab",
        "outputId": "64bce779-80e0-4b17-f954-bf0ef0d7b970"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2763, 0.5843, 0.1394]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "_hFxQE_4PTUp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "143n10q_OiFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}